# vim: ft=python
import os
import glob
import pandas
import itertools
from collections import defaultdict

configfile: 'totalRNA_config.yaml'
workdir: os.environ['PWD']
shell.executable('bash')


def input_files(wildcards):
    return d[wildcards.sampleID]


localrules: all, bam_text_file, filtered_count

rule all_qc:
    input:
        expand('merged/{sampleID}_merged_R1.fastq.gz', sampleID=d.keys()),
        'reports/filtered_read_count.tsv',


rule merge:
    input: input_files
    output: 
        'merged/{sampleID}_merged_R1.fastq.gz',
        'merged/{sampleID}_merged_R2.fastq.gz'
    threads: 4
    run:
        if config['need_merge'] == 'True':
            r1 = [x for x in input if '_R1' in x]
            r2 = [x for x in input if '_R2' in x]
            r1.sort()
            r2.sort()
            shell('cat %s > {output[0]}' %' '.join(r1))
            shell('cat %s > {output[1]}' %' '.join(r2))
        else:
            for fname in input:
                if '_R1' in fname:
                    shell('ln -s %s %s' %(fname, output[0]))
                elif '_R2' in fname:
                    shell('ln -s %s %s' %(fname, output[1]))


rule cutadapt:
    input: rules.merge.output
    output:
        R1 = 'trimmed/{sampleID}_trimmed_R1.fastq.gz',
        R2 = 'trimmed/{sampleID}_trimmed_R2.fastq.gz'
    log: 'multiqc/cutadapt/{sampleID}.cutadapt.log'
    threads: 20
    params: adapter = config['adapter_fa']
    run:
        shell('cutadapt -b {params.adapter} -B {params.adapter} --cores={threads} -o {output.R1} -p {output.R2} {input} > {log}')
        

rule pretrim_qc:
    input: rules.merge.output
    output: 'pretrim_qc/{sampleID}_merged_R1_fastqc.zip'
    threads: 8
    run:
        shell('fastqc {input} -t {threads} --outdir=pretrim_qc')


rule posttrim_qc:
    input: rules.cutadapt.output
    output: 'posttrim_qc/{sampleID}_trimmed_R1_fastqc.zip'
    threads: 8
    run:
        shell('fastqc {input} -t {threads} --outdir=posttrim_qc')


rule qc_multiqc:
    input: 
        expand('posttrim_qc/{sampleID}_trimmed_R1_fastqc.zip', sampleID=d.keys()),
        expand('pretrim_qc/{sampleID}_merged_R1_fastqc.zip', sampleID=d.keys())
    output: 'multiqc/qc_report.html'
    run:
        shell('multiqc -d pretrim_qc posttrim_qc -n qc_report -o multiqc')


rule filtered_count:
    input: rules.qc_multiqc.output
    output: 'reports/filtered_read_count.tsv'
    run:
        df = pandas.read_table('multiqc/qc_report_data/multiqc_general_stats.txt', sep='\t')
        # drop R2 files
        df = df[df['Sample'].str.contains('R1')]
        df['sampleID'] = df['Sample'].apply(lambda x: x.split(' | ')[1].split('_')[0])

        pre = df[df['Sample'].str.contains('pretrim')][['sampleID', 'FastQC_mqc-generalstats-fastqc-total_sequences']].copy()
        post = df[df['Sample'].str.contains('posttrim')][['sampleID', 'FastQC_mqc-generalstats-fastqc-total_sequences']].copy()

        dd = pre.merge(post, on='sampleID', suffixes=('_pre', '_post'))
        dd['lowq_reads'] = dd['FastQC_mqc-generalstats-fastqc-total_sequences_pre'].astype(float) - dd['FastQC_mqc-generalstats-fastqc-total_sequences_post'].astype(float)
        dd['lowq_perc'] = 100 - (dd['FastQC_mqc-generalstats-fastqc-total_sequences_post'].astype(float) / dd['FastQC_mqc-generalstats-fastqc-total_sequences_pre'].astype(float) * 100)

        shell('mkdir -p reports')
        dd.to_csv('reports/filtered_read_count.tsv', sep='\t', index=False)



